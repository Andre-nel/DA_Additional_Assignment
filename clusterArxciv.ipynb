{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, silhouette_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131565 entries, 0 to 131564\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   ID            131565 non-null  object\n",
      " 1   Date          131565 non-null  object\n",
      " 2   Title         131565 non-null  object\n",
      " 3   Abstract      131564 non-null  object\n",
      " 4   Subject_area  130671 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('arxiv2017.csv', delimiter=';')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Subject_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0912.5014v1</td>\n",
       "      <td>26/12/2009</td>\n",
       "      <td>A User's Guide to Zot</td>\n",
       "      <td>Zot is an agile and easily extendible bounded ...</td>\n",
       "      <td>LO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0910.0820v2</td>\n",
       "      <td>05/10/2009</td>\n",
       "      <td>Prediction of Zoonosis Incidence in Human usin...</td>\n",
       "      <td>Zoonosis refers to the transmission of infecti...</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1505.01933v1</td>\n",
       "      <td>08/05/2015</td>\n",
       "      <td>Wireless Multicast for Zoomable Video Streaming</td>\n",
       "      <td>Zoomable video streaming refers to a new class...</td>\n",
       "      <td>NI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1512.02794v2</td>\n",
       "      <td>09/12/2015</td>\n",
       "      <td>On Computing the Minkowski Difference of Zonot...</td>\n",
       "      <td>Zonotopes are becoming an increasingly popular...</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs_0701171v1</td>\n",
       "      <td>26/01/2007</td>\n",
       "      <td>The Zones Algorithm for Finding Points-Near-a-...</td>\n",
       "      <td>Zones index an N-dimensional Euclidian or metr...</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID        Date  \\\n",
       "0   0912.5014v1  26/12/2009   \n",
       "1   0910.0820v2  05/10/2009   \n",
       "2  1505.01933v1  08/05/2015   \n",
       "3  1512.02794v2  09/12/2015   \n",
       "4  cs_0701171v1  26/01/2007   \n",
       "\n",
       "                                               Title  \\\n",
       "0                              A User's Guide to Zot   \n",
       "1  Prediction of Zoonosis Incidence in Human usin...   \n",
       "2    Wireless Multicast for Zoomable Video Streaming   \n",
       "3  On Computing the Minkowski Difference of Zonot...   \n",
       "4  The Zones Algorithm for Finding Points-Near-a-...   \n",
       "\n",
       "                                            Abstract Subject_area  \n",
       "0  Zot is an agile and easily extendible bounded ...           LO  \n",
       "1  Zoonosis refers to the transmission of infecti...           LG  \n",
       "2  Zoomable video streaming refers to a new class...           NI  \n",
       "3  Zonotopes are becoming an increasingly popular...           CG  \n",
       "4  Zones index an N-dimensional Euclidian or metr...           DB  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB, NI, CR, CV\n",
    "# I want to extract these subject area rows from data and develop the clustering program using their data\n",
    "# in a controlled environment, evaluating the unsupervised clustering by the known clusters.\n",
    "selected_subjects = [\"DB\", \"NI\", \"CR\", \"CV\"]\n",
    "filtered_data = data[data['Subject_area'].isin(selected_subjects)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was thinking about combining the title and the abstract columns,\n",
    "# but i think it might be usefull to give more emphasis to the words in the\n",
    "# title than that of the abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text\n",
    "def preprocess_text(text: str, remove_stopwords: bool) -> str:\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove links\n",
    "    text = re.sub(\"[^A-Za-z]+\", \" \", text)  # Remove special characters and numbers\n",
    "    if remove_stopwords:\n",
    "        tokens = nltk.word_tokenize(text)  # Tokenize\n",
    "        tokens = [w for w in tokens if not w.lower() in stopwords.words(\"english\")]  # Remove stopwords\n",
    "        text = \" \".join(tokens)  # Join tokens\n",
    "    text = text.lower().strip()  # Convert to lowercase and remove whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data['cleaned'] = filtered_data['Title'].apply(lambda x: preprocess_text(x, remove_stopwords=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=2, max_df=0.95)\n",
    "\n",
    "X = vectorizer.transform(filtered_data['cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KMeans clustering with 3 clusters\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "# Fit the model\n",
    "kmeans.fit(X)\n",
    "# Store cluster labels in a variable\n",
    "clusters = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA with 2 components\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_vecs = pca.transform(X.toarray())\n",
    "x0 = pca_vecs[:, 0]\n",
    "x1 = pca_vecs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data['cluster'] = clusters\n",
    "filtered_data['x0'] = x0\n",
    "filtered_data['x1'] = x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_map = {0: \"Cluster 0\", 1: \"Cluster 1\", 2: \"Cluster 2\"}\n",
    "# filtered_data['cluster'] = filtered_data['cluster'].map(cluster_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
